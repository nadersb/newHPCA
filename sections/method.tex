
\newcommand{\icount}{\textsc{icount}\xspace}

To study the effects of ISAs on Power, Performance, and Area, we used several different metrics using 4 different tools and more than 12 standard benchmark applications. Followings describe the frameworks, metrics, and benchmarks used in this paper. The reader can skip this section if he/she is uninterested in these details. 

\subsection{ISAs and Compiler}
Table~\ref{t:isa} shows the ISAs used in study. For each of these ISAs, we use \textit{gnu-gcc} cross-compiler. We intentionally chose gcc so
that we can use the same front-end to generate all binaries. All
target independent optimizations are enabled (O3); machine specific
tuning is disabled so there is a single set of binaries for each ISA. For MIPS, \textit{-march} is used to generate MIPS release 6, 32bit and 64bit versions. For ARM, two separate compilers ARMv7 and AARCHv8 are used to generate 32bit and 64bit ARM binaries. Finally, for RISCV we use the gnu-toolchain provided by RISCV developers publicly available in github. We believe using similar flags and front-end could help us to mitigate the effect of compilers on performance and power metrics, however, we will later show that RISCV compiler does have important inefficiencies and issues that could hurt the performance of the system. 

\begin{table}[h]
\centering
\caption{ISAs used in this study.}
\begin{tabular}{|c|c|}
\hline
%\multicolumn{3}{ |c| }{Team sheet} \\
\small \textbf{ISAs} & \small \textbf{Specification} \\
\hline \hline
\small ARM & \small  32v7, 64v8 (AARCH) \\
\hline
\small MIPS & \small 32r6, 64r6 \\
\hline
\small RISCV &\small  rv32g (IMAFD), rv64g \\
\hline
\end{tabular}
\label{t:isa}
\end{table}

\subsection{Framework} 
\subsubsection{QEMU}
To find the dynamic and static instruction count (\icount), we use a well-known open-source emulator called QuickEMUlator (QEMU). QEMU is a hosted virtual machine monitor: it emulates the machine's processor through dynamic binary translation and provides a set of different hardware and device models for the machine, enabling it to run a variety of guest operating systems. We chose QEMU primarily cause it can emulates MIPS, ARM, and RISCV ISAs in user-mode. 



\noindent \textbf{Static Instruction Count}: Static icount is a classic metric to show the code density of different ISAs which can directly affect the performance, power, and area (i.e. required icache size). While static icount can simply be measured by measuring the lines of assembly code in a binary, a more meaningful and useful way to measure this metric is to count number of unique PCs (each PC represents an instruction) seen during the execution of the an application (i.e. counting only those instructions that are actually executed at least once). We believe this approach provides a better insight on the actual instruction memory footprint and shows the difference between ISAs better. We found that these two number (our approach vs. measuring the size of the code) could be quite different for some applications since compilers might include source codes for all routines in an included library, while some of these routines may not be used at all.  

To find static icount, we modified QEMU's source code to add a new data structure to track and count unique PCs during the execution. These changes are made in a routine called \textsc{exec\_cpu()} which is used in all ISAs. To check the correctness of our model, for each ISA, we used several synthetic benchmarks and checked the QEMU's output to the actual static icount computed manually. 

\noindent \textbf{Dynamic Instruction Count}: Similar to static icount, dynamic icount is also an important metric to show the runtime behavior of ISAs. Dynamic icount can directly affect total runtime especially in simple in-order cores where Instruction Per Cycle (IPC) for these cores are mostly close to 1 thus the total runtime is determined by dynamic icount metric. 

Dynamic icount is also computed in QEMU by modifying the source code to be able to count this metric during execution. The results are validated using a synthetic benchmark where number of iterations of a simple loop changed in different runs. We checked whether QEMU correctly reports dynamic icount as the number of iterations changed for each run. 

\noindent \textbf{Per-PC Iteration Count}: Another interesting metric which used in this paper is per-PC iteration count where for each PC we report how many times this instruction has been executed. This could be very useful to find the hot regions in the code, and find the reason(s) behind why some applications have significantly higher/lower dynamic icount. More details will be shown in the Section ??. QEMU is modified to count this metric too, during execution. 

\subsubsection{gem5}
gem5 is a well-known, open-source, cycle-accurate simulator which can simulate in-order and out-of-order cores, memory systems, and interconnect in details. Using gem5 enables us to find runtime statistics (e.g total number of cycles) and micro-architecture related statistics (e.g. cache miss rate). gem5 supports ARM and very recently RISCV. Unfortunately gem5 only supports an old version of MIPS and hence we removed the analysis for MIPS in gem5. To have a fair comparison, processor and memory system configurations (i.e. clock rate, issue width, cache levels and size, delays, etc.) are matched for both ARM and RISCV processors. We use a simple single-issue, 4-stage pipeline with no prefetcher and a single-level cache as an in-order core for RISCV and ARM, and use a more sophisticated 4-issue, out-of-order, with a direct/indirect prefetcher and two level caches as an out-of-order core in our experiments. Detailed for these two cores are shown in Table~\ref{t:config}.

\begin{table}[h]
\caption{Simulation configuration for gem5.}
\begin{tabular}{|c|c|c|}
\hline
%\multicolumn{3}{ |c| }{Team sheet} \\
\small \textbf{Parameters} &\small \textbf{In-order core} &\small \textbf{Out-of-Order core} \\
\hline \hline
\small Issue Width & \small 1 & \small 4 \\
\hline
\small Private Caches & \small I\$/D\$ 32KB & \small I\$/D\$ 32KB\\
\hline
\small Shared Caches & \small N/A & \small L2 256KB \\
\hline
\small Branch Predictor & \small N/A & \small Tournament BP and BTB \\
\hline
\small Prefetcher & \small N/A & \small stride/next-line prefetcher \\
\hline
\end{tabular}
\label{t:config}
\end{table}

\noindent \textbf{Cycle Count and IPC}: we use the number reported by gem5 for these metrics. Same input is used for both RISCV and ARM and the numbers reported are from beginning to end of each application. We use IPC to show the effect of using different ISAs on processor's computation speed. Our key findings about these two numbers will be shown in Section ??. 

\noindent \textbf{Microarchitecture Statistics}: to gain some insights about the runtime behavior of each core and ISA's impacts on them, we check several microarchitecture-related metrics such as: cache miss rate (MPKI), branch predictor accuracy, instruction mix, fetch and commit rates, total stall/idle/squashed cycles, memory bandwidth utilization, direct/indirect branches and function calls, and dependent memory load/stores across different applications. 

\subsubsection{McPAT}
McPAT is an integrated power and area modeling simulator. It uses ITRS roadmap models at circuit level to model both static and dynamic power of the system. McPAT uses an XML-based interface to read microarchitecture-related statistics generated by a cycle-accurate simulator (e.g. gem5) as inputs and uses a detailed model for cores, memory system, NoC, etc. to estimate the area and power of the system. We use a set of python and shell scripts to parse the statistics from gem5 and fill in the XML template in McPAT.  

\noindent \textbf{Dynamic Power and Total Energy}: using McPAT, we measure the dynamic power consumption of core (both in-order and out-of-order) and memory system. Using the data from gem5, we also calculate the overall energy for these ISAs.

\subsection{Applications}
We use a representative set of applications from a standard open-source embedded system's benchmark suite called MiBench. The MiBench suite is commonly used to evaluate the performance of processors intended for the embedded/IoT market, and it was designed to be representative of the computation that is needed in that market (e.g. automotive, industrial systems, etc.). These applications are mostly compute intensive and designed such that have minimum interactions with outside the processors. Many of the applications are also overlapped with EEMBC benchmark suite. 

Our applications we picked ranges from basic math abilities (\textit{basicmath}), bit manipulation (\textit{bitcount}), simple data organization (\textit{qsort}), a shape recognition program (\textit{susan}), shortest path calculations (\textit{dijkstra}), to data encryption, decryption and hashing (\textit{blowfish, rijandael, sha}), and communications applications (\textit{fft, crc32, adpcm}). In addition to these 11 applications picked from MiBench, we use two well-known open-source application which often used in industry to report the performance of the processor \textit{Coremark} and \textit{Dhrystone}. For each of these applications the ``large'' dataset is used. For Coremark and Dhrystone, iterations are chosen such that the total number of executed instructions be more than 200 million instructions (we chose 1000 iterations for Coremark and 1 million iterations for Dhrystone). For each application, same inputs are used for all runs across different ISAs/processors. 

   
 
